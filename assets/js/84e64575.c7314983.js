"use strict";(self.webpackChunkpathling_site=self.webpackChunkpathling_site||[]).push([[323],{3905:(e,t,n)=>{n.d(t,{Zo:()=>c,kt:()=>m});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function s(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?s(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):s(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},s=Object.keys(e);for(a=0;a<s.length;a++)n=s[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(a=0;a<s.length;a++)n=s[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var i=a.createContext({}),p=function(e){var t=a.useContext(i),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},c=function(e){var t=p(e.components);return a.createElement(i.Provider,{value:t},e.children)},d="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},h=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,s=e.originalType,i=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),d=p(n),h=r,m=d["".concat(i,".").concat(h)]||d[h]||u[h]||s;return n?a.createElement(m,o(o({ref:t},c),{},{components:n})):a.createElement(m,o({ref:t},c))}));function m(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var s=n.length,o=new Array(s);o[0]=h;var l={};for(var i in t)hasOwnProperty.call(t,i)&&(l[i]=t[i]);l.originalType=e,l[d]="string"==typeof e?e:r,o[1]=l;for(var p=2;p<s;p++)o[p]=n[p];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}h.displayName="MDXCreateElement"},5162:(e,t,n)=>{n.d(t,{Z:()=>o});var a=n(7294),r=n(6010);const s="tabItem_Ymn6";function o(e){let{children:t,hidden:n,className:o}=e;return a.createElement("div",{role:"tabpanel",className:(0,r.Z)(s,o),hidden:n},t)}},5488:(e,t,n)=>{n.d(t,{Z:()=>h});var a=n(7462),r=n(7294),s=n(6010),o=n(2389),l=n(7392),i=n(7094),p=n(2466);const c="tabList__CuJ",d="tabItem_LNqP";function u(e){const{lazy:t,block:n,defaultValue:o,values:u,groupId:h,className:m}=e,b=r.Children.map(e.children,(e=>{if((0,r.isValidElement)(e)&&"value"in e.props)return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})),f=u??b.map((e=>{let{props:{value:t,label:n,attributes:a}}=e;return{value:t,label:n,attributes:a}})),g=(0,l.l)(f,((e,t)=>e.value===t.value));if(g.length>0)throw new Error(`Docusaurus error: Duplicate values "${g.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`);const v=null===o?o:o??b.find((e=>e.props.default))?.props.value??b[0].props.value;if(null!==v&&!f.some((e=>e.value===v)))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${v}" but none of its children has the corresponding value. Available values are: ${f.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);const{tabGroupChoices:k,setTabGroupChoices:y}=(0,i.U)(),[S,w]=(0,r.useState)(v),N=[],{blockElementScrollPositionUntilNextRender:T}=(0,p.o5)();if(null!=h){const e=k[h];null!=e&&e!==S&&f.some((t=>t.value===e))&&w(e)}const x=e=>{const t=e.currentTarget,n=N.indexOf(t),a=f[n].value;a!==S&&(T(t),w(a),null!=h&&y(h,String(a)))},D=e=>{let t=null;switch(e.key){case"Enter":x(e);break;case"ArrowRight":{const n=N.indexOf(e.currentTarget)+1;t=N[n]??N[0];break}case"ArrowLeft":{const n=N.indexOf(e.currentTarget)-1;t=N[n]??N[N.length-1];break}}t?.focus()};return r.createElement("div",{className:(0,s.Z)("tabs-container",c)},r.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,s.Z)("tabs",{"tabs--block":n},m)},f.map((e=>{let{value:t,label:n,attributes:o}=e;return r.createElement("li",(0,a.Z)({role:"tab",tabIndex:S===t?0:-1,"aria-selected":S===t,key:t,ref:e=>N.push(e),onKeyDown:D,onClick:x},o,{className:(0,s.Z)("tabs__item",d,o?.className,{"tabs__item--active":S===t})}),n??t)}))),t?(0,r.cloneElement)(b.filter((e=>e.props.value===S))[0],{className:"margin-top--md"}):r.createElement("div",{className:"margin-top--md"},b.map(((e,t)=>(0,r.cloneElement)(e,{key:t,hidden:e.props.value!==S})))))}function h(e){const t=(0,o.Z)();return r.createElement(u,(0,a.Z)({key:String(t)},e))}},1316:(e,t,n)=>{n.d(t,{_6:()=>o,fB:()=>r,t8:()=>s});var a=n(7294);const r=()=>a.createElement("p",null,"To use the Pathling encoders from Python, install the"," ",a.createElement("a",{href:"https://pypi.org/project/pathling/"},"pathling")," package using"," ",a.createElement("a",{href:"https://pip.pypa.io/"},"pip"),". Note that Java 11 is required, with your"," ",a.createElement("code",null,"JAVA_HOME")," properly set."),s=()=>a.createElement("p",null,"To use the Pathling encoders from Scala, install the ",a.createElement("code",null,"au.csiro.pathling:encoders")," ",a.createElement("a",{href:"https://maven.apache.org/"},"Maven")," package."),o=()=>a.createElement("p",null,"To use the Pathling encoders from Java, install the ",a.createElement("code",null,"au.csiro.pathling:encoders")," ",a.createElement("a",{href:"https://maven.apache.org/"},"Maven")," package.")},7030:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>d,contentTitle:()=>p,default:()=>m,frontMatter:()=>i,metadata:()=>c,toc:()=>u});var a=n(7462),r=(n(7294),n(3905)),s=n(5488),o=n(5162),l=n(1316);const i={sidebar_position:2},p="FHIR encoders",c={unversionedId:"libraries/encoders",id:"libraries/encoders",title:"FHIR encoders",description:"The Pathling library can be used to transform FHIR Bundles or NDJSON into Spark",source:"@site/docs/libraries/encoders.md",sourceDirName:"libraries",slug:"/libraries/encoders",permalink:"/docs/libraries/encoders",draft:!1,editUrl:"https://github.com/aehrc/pathling/tree/main/site/docs/libraries/encoders.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"libraries",previous:{title:"Introduction",permalink:"/docs/libraries/"},next:{title:"Terminology functions",permalink:"/docs/libraries/terminology"}},d={},u=[{value:"Reading in NDJSON",id:"reading-in-ndjson",level:2},{value:"Reading in Bundles",id:"reading-in-bundles",level:2}],h={toc:u};function m(e){let{components:t,...n}=e;return(0,r.kt)("wrapper",(0,a.Z)({},h,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"fhir-encoders"},"FHIR encoders"),(0,r.kt)("p",null,"The Pathling library can be used to transform ",(0,r.kt)("a",{parentName:"p",href:"https://hl7.org/fhir"},"FHIR")," Bundles or NDJSON into Spark\ndata sets. Once your data is encoded, it can be queried using SQL, or\ntransformed using the full library of functions that Spark provides. It can also\nbe written to ",(0,r.kt)("a",{parentName:"p",href:"https://parquet.apache.org/"},"Parquet")," and other formats that are\ncompatible with a wide range of tools. See\nthe ",(0,r.kt)("a",{parentName:"p",href:"https://spark.apache.org/docs/latest/"},"Spark documentation")," for more\ndetails."),(0,r.kt)("h2",{id:"reading-in-ndjson"},"Reading in NDJSON"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"http://ndjson.org"},"NDJSON")," is a format commonly used for bulk FHIR data, and\nconsists of files (one per resource type) that contains one JSON resource per\nline."),(0,r.kt)(s.Z,{mdxType:"Tabs"},(0,r.kt)(o.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,r.kt)(l.fB,{mdxType:"PythonInstallation"}),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from pathling import PathlingContext\n\npc = PathlingContext.create()\n\n# Read each line from the NDJSON into a row within a Spark data set.\nndjson_dir = '/some/path/ndjson/'\njson_resources = pc.spark.read.text(ndjson_dir)\n\n# Convert the data set of strings into a structured FHIR data set.\npatients = pc.encode(json_resources, 'Patient')\n\n# Do some stuff.\npatients.select('id', 'gender', 'birthDate').show()\n"))),(0,r.kt)(o.Z,{value:"scala",label:"Scala",mdxType:"TabItem"},(0,r.kt)(l.t8,{mdxType:"ScalaInstallation"}),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import au.csiro.pathling.library.PathlingContext\n\nval spark = SparkSession.builder.getOrCreate()\n\n// Read each line from the NDJSON into a row within a Spark data set.\nval ndjsonDir = "/some/path/ndjson/"\nval jsonResources = spark.read.text(ndjsonDir)\n\n// Convert the data set of strings into a structured FHIR data set.\nval pc = PathlingContext.create(spark)\nval patients = pc.encode(jsonResources, "Patient")\n\n// Do some stuff.\npatients.select("id", "gender", "birthDate").show()\n'))),(0,r.kt)(o.Z,{value:"java",label:"Java",mdxType:"TabItem"},(0,r.kt)(l._6,{mdxType:"JavaInstallation"}),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-java"},'import org.apache.spark.sql.SparkSession;\nimport org.apache.spark.sql.Dataset;\nimport au.csiro.pathling.library.PathlingContext;\n\nclass MyApp {\n\n    public static void main(String args[]) {\n        SparkSession spark = SparkSession.builder().getOrCreate();\n\n        // Read each line from the NDJSON into a row within a Spark data set.\n        String ndjsonDir = "/some/path/ndjson/";\n        Dataset<Row> jsonResources = spark.read().text(ndjsonDir);\n\n        // Convert the data set of strings into a structured FHIR data set.\n        PathlingContext pc = PathlingContext.create(spark);\n        Dataset<Row> patients = pc.encode(jsonResources, "Patient");\n\n        // Do some stuff.\n        patients.select("id", "gender", "birthDate").show();\n    }\n\n}\n')))),(0,r.kt)("h2",{id:"reading-in-bundles"},"Reading in Bundles"),(0,r.kt)("p",null,"The FHIR ",(0,r.kt)("a",{parentName:"p",href:"https://hl7.org/fhir/R4/bundle.html"},"Bundle")," resource can contain a\ncollection of FHIR resources. It is often used to represent a set of related\nresources, perhaps generated as part of the same event."),(0,r.kt)(s.Z,{mdxType:"Tabs"},(0,r.kt)(o.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,r.kt)(l.fB,{mdxType:"PythonInstallation"}),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from pathling import PathlingContext\n\npc = PathlingContext.create()\n\n# Read each Bundle into a row within a Spark data set.\nbundles_dir = '/some/path/bundles/'\nbundles = pc.spark.read.text(bundles_dir, wholetext=True)\n\n# Convert the data set of strings into a structured FHIR data set.\npatients = pc.encode_bundle(bundles, 'Patient')\n\n# JSON is the default format, XML Bundles can be encoded using input type.\n# patients = pc.encodeBundle(bundles, 'Patient', inputType=MimeType.FHIR_XML)\n\n# Do some stuff.\npatients.select('id', 'gender', 'birthDate').show()\n"))),(0,r.kt)(o.Z,{value:"scala",label:"Scala",mdxType:"TabItem"},(0,r.kt)(l.t8,{mdxType:"ScalaInstallation"}),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import org.apache.spark.sql.SparkSession\nimport au.csiro.pathling.library.PathlingContext\n\nval spark = SparkSession.builder.getOrCreate()\n\n// Read each line from the NDJSON into a row within a Spark data set.\nval bundlesDir = "/some/path/bundles/"\nval bundles = spark.read.option("wholetext", value = true).text(bundlesDir)\n\n// Convert the data set of strings into a structured FHIR data set.\nval pc = PathlingContext.create(spark)\nval patients = pc.encodeBundle(bundles, "Patient")\n\n// JSON is the default format, XML Bundles can be encoded using input type.\n// val patients = pc.encodeBundle(bundles, "Patient", FhirMimeTypes.FHIR_XML)\n\n// Do some stuff.\npatients.select("id", "gender", "birthDate").show()\n'))),(0,r.kt)(o.Z,{value:"java",label:"Java",mdxType:"TabItem"},(0,r.kt)(l._6,{mdxType:"JavaInstallation"}),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-java"},'import org.apache.spark.sql.SparkSession;\nimport org.apache.spark.sql.Dataset;\nimport au.csiro.pathling.library.PathlingContext;\n\nclass MyApp {\n\n    public static void main(String args[]) {\n        SparkSession spark = SparkSession.builder().getOrCreate();\n\n        // Read each line from the NDJSON into a row within a Spark data set.\n        String bundlesDir = "/some/path/bundles/";\n        Dataset<Row> bundles = spark.read()\n                .option("wholetext", true)\n                .text(bundlesDir);\n\n        // Convert the data set of strings into a structured FHIR data set.\n        PathlingContext pc = PathlingContext.create(spark);\n        Dataset<Row> patients = pc.encodeBundle(bundles, "Patient");\n\n        // JSON is the default format, XML Bundles can be encoded using input \n        // type.\n        // Dataset<Row> patients = pc.encodeBundle(bundles, "Patient", \n        //     FhirMimeTypes.FHIR_XML);\n\n        // Do some stuff.\n        patients.select("id", "gender", "birthDate").show();\n    }\n\n}\n')))))}m.isMDXComponent=!0}}]);