spring:
  profiles:
    active:
      - core
      - server

pathling:
  # Controls the description of this server as displayed within the FHIR CapabilityStatement.
  implementationDescription: Yet Another Pathling Server

  # If this variable is set, all errors will be reported to a Sentry service, e.g.
  # `https://abc123@sentry.io/123456`.
  # sentryDsn: [Sentry DSN]

  # This variable sets the environment that each Sentry report is tagged with.
  # sentryEnvironment: [environment]

  spark:
    # The name that Pathling will be identified as within the Spark cluster.
    appName: pathling

    # Setting this option to true will enable additional logging relating to the query plan used to
    # execute queries.
    explainQueries: false

    # This controls whether the built-in caching within Spark is used for resource datasets and
    # search results. It may be useful to turn this off for large datasets in memory-constrained
    # environments.
    cacheDatasets: true

    # When a table is updated, the number of partitions is checked. If the number exceeds this
    # threshold, the table will be repartitioned back to the default number of partitions. This
    # prevents large numbers of small updates causing poor subsequent query performance.
    compactionThreshold: 10

  storage:
    # The base URL at which Pathling will look for data files, and where it will save data received
    # within import requests. Can be an Amazon S3 (s3://), HDFS (hdfs://) or filesystem (file://)
    # URL.
    warehouseUrl: file:///usr/share/warehouse

    # The subdirectory within the warehouse path used to read and write data.
    databaseName: default

  terminology:
    # Enables the use of terminology functions.
    enabled: true

    # The endpoint of a FHIR terminology service (R4) that the server can use to resolve terminology
    # queries. The server listed here is suitable for testing purposes only.
    serverUrl: https://tx.ontoserver.csiro.au/fhir

    # Setting this option to true will enable additional logging of the details of requests between
    # the server and the terminology service.
    verboseLogging: false

    # Configuration relating to the HTTP client used for terminology requests.
    client:
      # The maximum period (in milliseconds) that the server should wait for incoming data from the
      # terminology service.
      socketTimeout: 60_000

      # The maximum number of connections that the server should open to the terminology service.
      maxConnectionsTotal: 32

      # The maximum number of connections that the server should open to the terminology service,
      # per route.
      maxConnectionsPerRoute: 16

      # Controls whether terminology requests that fail for possibly transient reasons (network
      # connections, DNS problems) should be retried.
      retryEnabled: true

      # The number of times to retry failed terminology requests.
      retryCount: 2

    # Configuration relating to the caching of terminology requests.
    cache:
      # Set this to false to disable caching of terminology requests (not recommended).
      enabled: true

      # The type of storage to use for the cache. Can be "memory" or "disk".
      storageType: "memory"

      # Sets the maximum number of entries that will be held in memory. Only applicable when using
      # the "memory" storage type.
      maxEntries: 200_000

      # The path on disk to use for the cache, required when a storage type of "disk" is specified.
      # storagePath: /usr/share/cache

      # The default expiry time for cache entries (in seconds), used when the server does not
      # provide an expiry value.
      defaultExpiry: 600

      # If provided, this value overrides the expiry time provided by the terminology server.
      # overrideExpiry: 2592000

    # Configuration relating to authentication of requests to the terminology service.
    authentication:
      # Enables authenticated requests.
      enabled: false

      # Authentication details for use with the client credentials grant.
      # tokenEndpoint: [token endpoint]
      # clientId: [client ID]
      # clientSecret: [client secret]

      # The minimum number of seconds that a token should have before expiry when deciding whether
      # to send it with a terminology request.
      tokenExpiryTolerance: 120

  auth:
    # Enables authorization.
    enabled: false

    # Configures the issuing domain for bearer tokens, which will be checked against the claims
    # within incoming bearer tokens.
    # issuer: [issuer]

    # Configures the audience for bearer tokens, which is the FHIR endpoint that tokens are
    # intended to be authorised for.
    # audience: [audience]

    # Provides the URL which will be advertised as the authorization endpoint.
    # authorizeUrl: [authorization URL]

    # Provides the URL which will be advertised as the token endpoint.
    # tokenUrl: [token URL]

    # Provides the URL which will be advertised as the token revocation endpoint.
    # revokeUrl: [token revocation URL]

    ga4ghPassports:
      # When GA4GH passport authentication is enabled, this option configures the identifier system
      # that is used to identify and control access to patient data.
      patientIdSystem: http://www.australiangenomics.org.au/id/study-number

      # When GA4GH passport authentication is enabled, this option configures the list of endpoints
      # that are allowed to issue visas.
      allowedVisaIssuers: []

  # This section configures HTTP caching response headers.
  httpCaching:
    # A list of values to return within the Vary header.
    vary:
      - Accept
      - Accept-Encoding
      - Prefer
      - Authorization
    # A list of values to return within the Cache-Control header, for cacheable responses.
    cacheableControl:
      - must-revalidate
      - max-age=1
    # A list of values to return within the Cache-Control header, for uncacheable responses.
    uncacheableControl:
      - no-store

  # This section configures the CORS functionality of the server.
  # For more information, see: https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS
  cors:
    allowedOrigins: []
    allowedOriginPatterns: []
    allowedMethods:
      - OPTIONS
      - GET
      - POST
    allowedHeaders:
      - Content-Type
      - Authorization
      - Prefer
    exposedHeaders:
      - Content-Location
      - X-Progress
    maxAge: 600

  import:
    allowableSources:
      - "file:///usr/share/staging"

  async:
    enabled: true

  encoding:
    # Controls the maximum depth of nested element data that is encoded upon import.
    maxNestingLevel: 3

    # Enables support for FHIR extensions.
    enableExtensions: true

    # The list of types that are encoded within open types, such as extensions. This default list
    # was taken from the data types that are common to extensions found in widely-used IGs,
    # such as the US and AU base profiles. In general, you will get the best query performance by
    # encoding your data with the shortest possible list.
    openTypes:
      - boolean
      - code
      - date
      - dateTime
      - decimal
      - integer
      - string
      - Coding
      - CodeableConcept
      - Address
      - Identifier
      - Reference

# Use this section to set or override any Spark configuration parameter. Tuning these parameters is
# essential to get the optimal performance for your dataset.
# Here is the full list: https://spark.apache.org/docs/latest/configuration.html
spark:
  master: local[*]
  sql:
    adaptive:
      enabled: true
      coalescePartitions:
        enabled: true
    extensions: io.delta.sql.DeltaSparkSessionExtension
    catalog:
      spark_catalog: org.apache.spark.sql.delta.catalog.DeltaCatalog
  databricks:
    delta:
      schema:
        autoMerge:
          enabled: true
  scheduler:
    mode: FAIR

# Use this section to set or override configuration relating to S3 configuration.
# See: https://hadoop.apache.org/docs/stable/hadoop-aws/tools/hadoop-aws/index.html
fs:
  s3a:
    aws:
    # credentials:
    #   provider: org.apache.hadoop.fs.s3a.AnonymousAWSCredentialsProvider
    #   provider: org.apache.hadoop.fs.s3a.auth.AssumedRoleCredentialProvider
    #
    # For use with: SimpleAWSCredentialsProvider
    # access:
    #   key: [access key]
    # secret:
    #   key: [secret key]
    #
    # For use with: AssumedRoleCredentialProvider
    # assumed:
    #   role:
    #     arn: [role ARN]
    #
    connection:
      maximum: 100
    committer:
      name: magic
      magic:
        enabled: true
